# DepthCam Project

> üåê **Ng√¥n ng·ªØ | Language:**  
> [üáªüá≥ Ti·∫øng Vi·ªát](#n·ªôi-dung-ti·∫øng-vi·ªát) | [üá∫üá∏ English](#english-content)

---

## N·ªôi dung ti·∫øng Vi·ªát

# D·ª± √°n DepthCam - H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng v√† gi·∫£i th√≠ch m√£ ngu·ªìn

## T·ªïng quan
D·ª± √°n n√†y s·ª≠ d·ª•ng camera Intel RealSense D435 k·∫øt h·ª£p v·ªõi c√°c m√¥ h√¨nh AI (YOLO) ƒë·ªÉ th·ª±c hi·ªán c√°c t√°c v·ª• nh∆∞: nh·∫≠n di·ªán ƒë·ªëi t∆∞·ª£ng, ƒëo kho·∫£ng c√°ch, ƒëo chi·ªÅu cao, d·ª±ng point cloud 3D, v√† ƒë·ªçc d·ªØ li·ªáu IMU (c·∫£m bi·∫øn chuy·ªÉn ƒë·ªông). D∆∞·ªõi ƒë√¢y l√† gi·∫£i th√≠ch chi ti·∫øt cho t·ª´ng file Python trong t·ª´ng th∆∞ m·ª•c.

---

## Th∆∞ m·ª•c g·ªëc

### `convert.py`
- **Ch·ª©c nƒÉng:** Ch·∫°y th·ª≠ nghi·ªám m√¥ h√¨nh YOLO (yolo11n.pt) tr√™n webcam (source=0), hi·ªÉn th·ªã k·∫øt qu·∫£ nh·∫≠n di·ªán ƒë·ªëi t∆∞·ª£ng tr·ª±c ti·∫øp.
- **√ù nghƒ©a:** D√πng ƒë·ªÉ ki·ªÉm tra nhanh m√¥ h√¨nh YOLO ƒë√£ ho·∫°t ƒë·ªông ƒë√∫ng ch∆∞a v√† chuy·ªÉn sang model convert.

#### Demo s·ª≠ d·ª•ng:
```python
from ultralytics import YOLO
model = YOLO(r"yolo11n.pt")
model.predict(source=0, imgsz=640, conf=0.7, show=True)
```

### `get_config.py`
- **Ch·ª©c nƒÉng:** Li·ªát k√™ th√¥ng tin chi ti·∫øt v·ªÅ c√°c thi·∫øt b·ªã RealSense ƒëang k·∫øt n·ªëi, bao g·ªìm c√°c c·∫£m bi·∫øn v√† c·∫•u h√¨nh stream m√† t·ª´ng c·∫£m bi·∫øn h·ªó tr·ª£.
- **√ù nghƒ©a:** H·ªØu √≠ch ƒë·ªÉ ki·ªÉm tra camera ƒë√£ k·∫øt n·ªëi, xem c√°c ch·∫ø ƒë·ªô stream kh·∫£ d·ª•ng.

#### Demo s·ª≠ d·ª•ng:
```python
import pyrealsense2 as rs
context = rs.context()
devices = context.query_devices()
for device in devices:
    print(device.get_info(rs.camera_info.name))
```

---

## Th∆∞ m·ª•c `IMU/`

### `camera_IMU.py`
- **Ch·ª©c nƒÉng:** ƒê·ªçc d·ªØ li·ªáu t·ª´ c·∫£m bi·∫øn IMU (gyro, accel) v√† stream m√†u c·ªßa camera. T√≠nh to√°n g√≥c pitch/roll d·ª±a tr√™n d·ªØ li·ªáu gyro, ch·ªâ c·∫≠p nh·∫≠t khi ph√°t hi·ªán chuy·ªÉn ƒë·ªông m·∫°nh (d·ª±a v√†o bi·∫øn thi√™n gia t·ªëc). Hi·ªÉn th·ªã g√≥c l√™n khung h√¨nh m√†u.
- **√ù nghƒ©a:** Gi√∫p quan s√°t tr·ª±c quan g√≥c nghi√™ng c·ªßa camera khi di chuy·ªÉn, ph·ª•c v·ª• c√°c ·ª©ng d·ª•ng robot, AR/VR, v.v.

#### Demo s·ª≠ d·ª•ng:
```python
# Ch·∫°y script ƒë·ªÉ xem g√≥c nghi√™ng tr·ª±c ti·∫øp tr√™n h√¨nh ·∫£nh
python IMU/camera_IMU.py
```

![Minh h·ªça](IMU/image.png)

### `get_IMU.py`
- **Ch·ª©c nƒÉng:** ƒê·ªçc d·ªØ li·ªáu IMU (gyro, accel), t√≠nh to√°n g√≥c pitch/roll t∆∞∆°ng t·ª± nh∆∞ tr√™n nh∆∞ng kh√¥ng hi·ªÉn th·ªã h√¨nh ·∫£nh, ch·ªâ in ra console.
- **√ù nghƒ©a:** D√πng cho debug nhanh ho·∫∑c c√°c ·ª©ng d·ª•ng ch·ªâ c·∫ßn d·ªØ li·ªáu g√≥c nghi√™ng.

#### Demo s·ª≠ d·ª•ng:
```python
python IMU/get_IMU.py
```

---

## Th∆∞ m·ª•c `distance_object/`

### `distance.py`
- **Ch·ª©c nƒÉng:** K·∫øt h·ª£p YOLO ƒë·ªÉ nh·∫≠n di·ªán ƒë·ªëi t∆∞·ª£ng tr√™n khung h√¨nh m√†u, ƒë·ªìng th·ªùi ƒëo kho·∫£ng c√°ch t·ª´ camera ƒë·∫øn ƒë·ªëi t∆∞·ª£ng (d√πng depth map). Kho·∫£ng c√°ch ƒë∆∞·ª£c l√†m m∆∞·ª£t b·∫±ng b·ªô l·ªçc s·ªë.
- **√ù nghƒ©a:** ·ª®ng d·ª•ng ƒëo kho·∫£ng c√°ch v·∫≠t th·ªÉ theo th·ªùi gian th·ª±c, v√≠ d·ª• robot tr√°nh v·∫≠t, ƒëo kho·∫£ng c√°ch ng∆∞·ªùi/v·∫≠t.

#### Demo s·ª≠ d·ª•ng:
```python
python distance_object/distance_multy_ob.py
```

![Minh h·ªça](distance_object/image.png)

---

## Th∆∞ m·ª•c `height_object/`

### `height_person.py`
- **Ch·ª©c nƒÉng:** Nh·∫≠n di·ªán ng∆∞·ªùi b·∫±ng YOLO, l·∫•y point cloud trong v√πng bbox, t√≠nh chi·ªÅu cao ng∆∞·ªùi d·ª±a tr√™n d·ªØ li·ªáu 3D, l·ªçc nhi·ªÖu b·∫±ng Kalman, b√π tr·ª´ sai s·ªë.
- **√ù nghƒ©a:** ƒêo chi·ªÅu cao ng∆∞·ªùi t·ª± ƒë·ªông, ·ª©ng d·ª•ng trong ki·ªÉm tra s·ª©c kh·ªèe, robot, v.v.

#### Demo s·ª≠ d·ª•ng:
```python
python height_object/height_person.py
```

![Minh h·ªça](height_object/image.png)

---

## Th∆∞ m·ª•c `education_demo/`

### `point_cloud.py`
- **Ch·ª©c nƒÉng:** D·ª±ng v√† hi·ªÉn th·ªã point cloud 3D t·ª´ camera RealSense, cho ph√©p xoay, zoom, d·ªãch chuy·ªÉn b·∫±ng chu·ªôt/ph√≠m. C√≥ th·ªÉ l∆∞u ·∫£nh, xu·∫•t file PLY.
- **√ù nghƒ©a:** Tr·ª±c quan h√≥a d·ªØ li·ªáu 3D, ph·ª•c v·ª• demo gi√°o d·ª•c, nghi√™n c·ª©u, ki·ªÉm tra ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu depth.

#### Demo s·ª≠ d·ª•ng:
```python
python education_demo/point_cloud.py
```

V√≠ d·ª• ·∫£nh minh h·ªça:
- ![Point cloud](education_demo/depth_color.png)
- ![Focus](education_demo/focus.png)
- ![K·∫øt qu·∫£](education_demo/out.png)

---

## Th∆∞ m·ª•c `model/`

### `yolo11n.pt`
- **Ch·ª©c nƒÉng:** File tr·ªçng s·ªë m√¥ h√¨nh YOLO11n ƒë√£ hu·∫•n luy·ªán, d√πng cho c√°c file nh·∫≠n di·ªán ƒë·ªëi t∆∞·ª£ng.
- **√ù nghƒ©a:** Kh√¥ng ch·ªânh s·ª≠a file n√†y, ch·ªâ d√πng ƒë·ªÉ n·∫°p v√†o c√°c script nh·∫≠n di·ªán.

---

## L∆∞u √Ω chung
- ƒê·ªÉ ch·∫°y ƒë∆∞·ª£c c√°c file, c·∫ßn c√†i ƒë·∫∑t c√°c th∆∞ vi·ªán: `pyrealsense2`, `opencv-python`, `ultralytics`, `numpy`, v.v.
- ƒê·∫£m b·∫£o ƒë√£ k·∫øt n·ªëi camera Intel RealSense D435 tr∆∞·ªõc khi ch·∫°y c√°c script.
- M·ªôt s·ªë file ·∫£nh (`image.png`, `focus.png`, ...) ch·ªâ d√πng minh h·ªça, kh√¥ng ·∫£nh h∆∞·ªüng code.

---

M·ªçi th·∫Øc m·∫Øc ho·∫∑c c·∫ßn h·ªó tr·ª£, vui l√≤ng li√™n h·ªá t√°c gi·∫£ d·ª± √°n [BaoHan1712](https://github.com/BaoHan1712)

---

## English Content

# DepthCam Project - User Guide and Source Code Explanation

## Overview
This project uses the Intel RealSense D435 camera combined with YOLO AI models to perform tasks such as object detection, distance measurement, height estimation, 3D point cloud rendering, and IMU (motion sensor) data reading. Below is a detailed explanation for each Python file in every folder.

---

## Root Folder

### `convert.py`
- **Function:** Test the YOLO (yolo11n.pt) model on webcam (source=0), display real-time object detection results.
- **Purpose:** Quickly check if the YOLO model is working and for model conversion.

#### Demo usage:
```python
from ultralytics import YOLO
model = YOLO(r"yolo11n.pt")
model.predict(source=0, imgsz=640, conf=0.7, show=True)
```

### `get_config.py`
- **Function:** List detailed information about connected RealSense devices, including sensors and supported stream profiles.
- **Purpose:** Useful for checking if the camera is connected and viewing available stream modes.

#### Demo usage:
```python
import pyrealsense2 as rs
context = rs.context()
devices = context.query_devices()
for device in devices:
    print(device.get_info(rs.camera_info.name))
```

---

## Folder `IMU/`

### `camera_IMU.py`
- **Function:** Read IMU (gyro, accel) data and color stream from the camera. Calculate pitch/roll angles based on gyro data, only updating when strong movement is detected (based on acceleration variation). Display angles on the color frame.
- **Purpose:** Visualize camera tilt in real time, useful for robotics, AR/VR, etc.

#### Demo usage:
```python
# Run the script to see real-time tilt angles on the image
python IMU/camera_IMU.py
```

![Demo](IMU/image.png)

### `get_IMU.py`
- **Function:** Read IMU (gyro, accel) data, calculate pitch/roll angles similarly but only print to console, no image display.
- **Purpose:** For quick debugging or applications that only need tilt data.

#### Demo usage:
```python
python IMU/get_IMU.py
```

---

## Folder `distance_object/`

### `distance.py`
- **Function:** Combine YOLO for object detection on the color frame and measure the distance from the camera to the object (using depth map). Distance is smoothed by a digital filter.
- **Purpose:** Real-time object distance measurement, e.g., for robot obstacle avoidance, measuring distance to people/objects.

#### Demo usage:
```python
python distance_object/distance_multy_ob.py
```

![Demo](distance_object/image.png)

---

## Folder `height_object/`

### `height_person.py`
- **Function:** Detect people using YOLO, extract point cloud in the bounding box, calculate height based on 3D data, filter noise with Kalman, and compensate for errors.
- **Purpose:** Automatic human height measurement, useful for health check, robotics, etc.

#### Demo usage:
```python
python height_object/height_person.py
```

![Demo](height_object/image.png)

---

## Folder `education_demo/`

### `point_cloud.py`
- **Function:** Render and display 3D point cloud from RealSense camera, allow rotation, zoom, translation with mouse/keyboard. Can save images or export PLY files.
- **Purpose:** Visualize 3D data, useful for education, research, or checking depth data quality.

#### Demo usage:
```python
python education_demo/point_cloud.py
```

Example images:
- ![Point cloud](education_demo/depth_color.png)
- ![Focus](education_demo/focus.png)
- ![Result](education_demo/out.png)

---

## Folder `model/`

### `yolo11n.pt`
- **Function:** Pretrained YOLO11n model weights, used for object detection scripts.
- **Purpose:** Do not modify this file, only load it in detection scripts.

---

## General Notes
- To run the scripts, install: `pyrealsense2`, `opencv-python`, `ultralytics`, `numpy`, etc.
- Make sure the Intel RealSense D435 camera is connected before running scripts.
- Some image files (`image.png`, `focus.png`, ...) are for illustration only, not required for code.

---

For any questions or support, please contact the project author [BaoHan1712](https://github.com/BaoHan1712)